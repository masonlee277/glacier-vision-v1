{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-04 22:41:34.081039: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-09-04 22:41:34.111388: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-04 22:41:34.111424: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-04 22:41:34.111430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-04 22:41:34.116716: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA_VISIBLE_DEVICES: None\n",
            "zsh:1: command not found: nvidia-smi\n",
            "TensorFlow version: 2.14.0\n",
            "Is built with CUDA: True\n",
            "WARNING:tensorflow:From /tmp/ipykernel_168618/1824185340.py:25: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "Is GPU available: False\n"
          ]
        }
      ],
      "source": [
        "from utils import *\n",
        "import os\n",
        "import shutil\n",
        "import wandb\n",
        "\n",
        "# Step 1: Clear Environment Variables\n",
        "os.environ.pop('WANDB_API_KEY', None)\n",
        "\n",
        "# Step 2: Clear Wandb Config Directory\n",
        "wandb_config_dir = os.path.expanduser(\"~/.config/wandb\")\n",
        "if os.path.exists(wandb_config_dir):\n",
        "    shutil.rmtree(wandb_config_dir)\n",
        "\n",
        "import os\n",
        "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get('CUDA_VISIBLE_DEVICES'))\n",
        "\n",
        "# Try to force TensorFlow to see the GPU\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Is built with CUDA:\", tf.test.is_built_with_cuda())\n",
        "print(\"Is GPU available:\", tf.test.is_gpu_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4uFC8PgMGcs"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hLWvCfdNXK_",
        "outputId": "9aa7da21-bbf8-4573-83cf-7802a474d917"
      },
      "outputs": [],
      "source": [
        "#!wandb login\n",
        "#8b97ec4737051e4f1eecd8716131bacbcaba5e15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "033b9ea94fb645bb8012a4189d53860b"
          ]
        },
        "id": "eg85rEBxMIIQ",
        "outputId": "08dd531c-faba-4c26-9455-1617e1ee55e4"
      },
      "outputs": [],
      "source": [
        "# ### this is how to\n",
        "\n",
        "# #train_model(model: tf.keras.Model, images_path: str, labels_path: str, working_dir: str, epochs=20, batch_size: int=32, pretrained_weights: str=None, resize_shape=512, fine_tune=False)\n",
        "# model = compile_model(512,512)\n",
        "# images_path='data/New_Data/tiles'\n",
        "# labels_path='data/New_Data/masks'\n",
        "# working_dir='data/model_weights/riverNet/RiverNet_checkpoint_dir/training_ft_1'\n",
        "# batch_size=12\n",
        "\n",
        "# #train_modelV1(model, images_path, labels_path, working_dir, epochs=100, batch_size=batch_size, pretrained_weights=None, resize_shape=512, fine_tune=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8wO903cqyDp"
      },
      "source": [
        "# Running Seg Connector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WPIgkVzrQ7P"
      },
      "source": [
        "## Define File Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_suHLaqiYby"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Setup Paths for Input and Output Directories\n",
        "----------------------------------------------\n",
        "\n",
        "In this section, we configure various paths used by our program. These paths are to the input, output, and model weights directories, and to the input TIFF file. We also specify the filename for the desired output file.\n",
        "\n",
        "Please make sure to replace these paths with the correct paths for your own project.\n",
        "\n",
        "Here is the purpose of each path:\n",
        "\n",
        "1. path: This is the root path where your project is located.\n",
        "2. output_dir: This is the path where you want to save your output files.\n",
        "3. input_dir: This is the path where your input files are located.\n",
        "4. model_weights_dir: This is the path where your model weights are located.\n",
        "5. input_tif_fp: This is the filepath to the input TIFF file that you want to process.\n",
        "6. desired_output_filename: This is the filename that you want to give to your output file.\n",
        "7. save_path: This is the full path where your output file will be saved.\n",
        "\n",
        "google bucket link: https://console.cloud.google.com/storage/browser/greenland_delin_imagery;tab=objects?prefix&forceOnObjectsSortingFiltering=false&pli=1\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "print(sys.version)\n",
        "\n",
        "# Path to the root directory of the project\n",
        "path = 'data/outputs'\n",
        "\n",
        "# Path to the output directory where the results will be saved\n",
        "output_dir = os.path.join(path, 'outputs')\n",
        "\n",
        "# Path to the input directory where the input files are located\n",
        "input_dir = os.path.join(path, 'inputs')\n",
        "\n",
        "# Filepath to the input TIFF file to be processed\n",
        "## Load the tif and preprocess for the model\n",
        "#input_tif_fp = 'data/sat_images/neiv-validation-data/WV03_20220801143842_1040010079411F00_22AUG01143842-M1BS-506796344080_01_P001_u16rf3413_RGB_COMP_CROPPED.tif'\n",
        "input_tif_fp = '/teamspace/studios/this_studio/data/mark_validation/clip_LC09_L2SP_006013_20220728_20230406_02_T1_RGB_COMP_cropped.tif'\n",
        "#input_tif_fp =  '/teamspace/studios/this_studio/data/mark_validation/clip_T22WEV_20220801T150809_RGB_COMP_10m_CROPPED.tif'\n",
        "#input_tif_fp = 'data/mark_validation/clip_WV03_20220801143842_1040010079411F00_22AUG01143842-M1BS-506796344080_01_P001_u16rf3413_RGB_COMP_CROPPED.tif'\n",
        "desired_output_filename = 'landsat_mark.tif'\n",
        "\n",
        "# Full path where the output file will be saved\n",
        "save_path = os.path.join(output_dir, desired_output_filename)\n",
        "\n",
        "\n",
        "# Function to create directory if it doesn't exist\n",
        "def create_directory(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Created directory: {directory}\")\n",
        "    else:\n",
        "        print(f\"Directory already exists: {directory}\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "create_directory(path)\n",
        "create_directory(output_dir)\n",
        "create_directory(input_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6JO-wzdkUKq"
      },
      "source": [
        "## Trained Model Intializaiton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63BdDWU4i79K",
        "outputId": "659b58cd-ed23-4907-c6ac-4a1a5bf1c092"
      },
      "outputs": [],
      "source": [
        "##########################################\n",
        "##using a single ml_model\n",
        "# ml_model = compile_model(512,512)\n",
        "# c =  \"/content/drive/My Drive/Projects/Mapping Glacial Rivers/Data/DB512v6/IOU/checkpoint_dir/cp-0008.ckpt\"\n",
        "# ml_model.load_weights(c)\n",
        "!ls 'data/model_weights/riverNet/RiverNet_checkpoint_dir/retiled_dice_loss_A100_no_aug-10-9-223'\n",
        "\n",
        "##########################################\n",
        "#model_weights_dir = \"/content/drive/My Drive/Projects/Mapping Glacial Rivers/Data/New_Data/training_dir/RiverNet_checkpoint_dir/retiled_dice_loss_A100_no_aug-10-9-223\"\n",
        "model_weights_dir = \"data/model_weights/riverNet/RiverNet_checkpoint_dir/retrained\"\n",
        "#ch = find_checkpoints(model_weights_dir,2)\n",
        "# ch= [os.path.join(model_weights_dir,\"model_weights_epoch_4.h5\"),\n",
        "#      os.path.join(model_weights_dir,\"model_weights_epoch_12.h5\"),\n",
        "#      os.path.join(model_weights_dir,\"model_weights_epoch_20.h5\"),\n",
        "#      os.path.join(model_weights_dir,\"model_weights_epoch_28.h5\")]\n",
        "\n",
        "ch= [os.path.join(model_weights_dir,\"model_weights_epoch_80.h5\"),\n",
        "     os.path.join(model_weights_dir,\"model_weights_epoch_70.h5\"),\n",
        "     os.path.join(model_weights_dir,\"model_weights_epoch_90.h5\"),\n",
        "     os.path.join(model_weights_dir,\"model_weights_epoch_100.h5\")]\n",
        "\n",
        "riverNet_model_list = []\n",
        "for c in ch:\n",
        "   print(c) #all the epochs of the checkpoints\n",
        "   ml_model = compile_model(512,512)\n",
        "   ml_model.load_weights(c)\n",
        "   riverNet_model_list.append(ml_model)\n",
        "\n",
        "\n",
        "##########################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import wandb\n",
        "# import wandb\n",
        "# wandb.api.clear_setting('api_key')\n",
        "# # Force re-login\n",
        "# wandb.login(relogin=True)\n",
        "# # Step 1: Log out of the current session\n",
        "# import wandb\n",
        "\n",
        "# run = wandb.init()\n",
        "# artifact = run.use_artifact('northern-change/segconnectorv2/model-training_on_RiverNet_PredictionsV2:v29', type='model')\n",
        "# artifact_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /teamspace/studios/this_studio/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwandaslaya\u001b[0m (\u001b[33mnorthern-change\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.8 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/teamspace/studios/this_studio/wandb/run-20240904_224247-8f8p7zlr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/northern-change/this_studio/runs/8f8p7zlr/workspace' target=\"_blank\">northern-oath-1</a></strong> to <a href='https://wandb.ai/northern-change/this_studio' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/northern-change/this_studio' target=\"_blank\">https://wandb.ai/northern-change/this_studio</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/northern-change/this_studio/runs/8f8p7zlr/workspace' target=\"_blank\">https://wandb.ai/northern-change/this_studio/runs/8f8p7zlr/workspace</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-training_on_own_predictions:v35, 51.78MB. 5 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n",
            "Done. 0:0:1.7\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "import wandb\n",
        "wandb.api.clear_setting('api_key')\n",
        "# Force re-login\n",
        "wandb.login(relogin=True)\n",
        "# Step 1: Log out of the current session\n",
        "import wandb\n",
        "\n",
        "run = wandb.init()\n",
        "artifact = run.use_artifact('northern-change/segconnectorv2/model-training_on_own_predictions:v35', type='model')\n",
        "artifact_dir = artifact.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WU5ZYxQ6Sdvp"
      },
      "outputs": [],
      "source": [
        "## Load seg_connector which is saved as a wandb artifact \n",
        "seg_connector = tf.keras.models.load_model(\n",
        "    'data/model_weights/segConnector/wandb_artifacts/model-training_on_RiverNet_PredictionsV2:v29',\n",
        "    custom_objects={'mean_iou': mean_iou,\n",
        "                    'dice_loss': dice_lossV1}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4V7WX6_A27E"
      },
      "source": [
        "## Set Up Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input = open_tiff(input_tif_fp)\n",
        "input = normalize_to_8bit(input)\n",
        "display(input)# Desired filename for the output file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgT44TAlemaG",
        "outputId": "a1e48324-3133-447a-9332-d5fd25ff5d4f"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "import multiprocessing\n",
        "#Manages the chunk memory efficiently for predicting on large tifs, should be able to scale to huge images\n",
        "pred_map = full_prediction_tiff(input, save_path, riverNet_model_list, seg_connector)\n",
        "transfer_metadata(input_tif_fp, pred_map, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(pred_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_map.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.unique(pred_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_overlay(base_image, overlay_image, figsize=(20, 7)):\n",
        "    \"\"\"\n",
        "    Display a base image, a binary overlay, and their combination in three subplots.\n",
        "    \n",
        "    Args:\n",
        "    base_image (np.ndarray): The base image to display. Can have multiple channels.\n",
        "    overlay_image (np.ndarray): The binary image to overlay. Should be 2D.\n",
        "    figsize (tuple): Size of the output figure in inches. Default is (20, 7).\n",
        "    \n",
        "    Returns:\n",
        "    None: Displays the resulting image.\n",
        "    \"\"\"\n",
        "    # Ensure images are numpy arrays\n",
        "    base_image = np.array(base_image)\n",
        "    overlay_image = np.array(overlay_image)\n",
        "    \n",
        "    # Handle different channel configurations\n",
        "    if base_image.ndim == 2:\n",
        "        base_image = np.stack([base_image] * 3, axis=-1)\n",
        "    elif base_image.shape[-1] not in [3, 4]:\n",
        "        raise ValueError(\"Base image must have 1, 3, or 4 channels\")\n",
        "    \n",
        "    if overlay_image.ndim != 2:\n",
        "        raise ValueError(\"Overlay image must be 2D\")\n",
        "    \n",
        "    # Create a mask for positive values\n",
        "    mask = overlay_image > 0.5\n",
        "    \n",
        "    # Create an RGBA overlay\n",
        "    overlay_rgba = np.zeros(base_image.shape[:2] + (4,))\n",
        "    overlay_rgba[mask, 0] = 1  # Red for positive values\n",
        "    overlay_rgba[mask, 3] = 0.5  # 50% opacity for positive values\n",
        "    \n",
        "    # Display the result\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=figsize)\n",
        "    \n",
        "    # Base image\n",
        "    ax1.imshow(base_image[..., :3])\n",
        "    ax1.set_title(\"Base Image\")\n",
        "    ax1.axis('off')\n",
        "    \n",
        "    # Binary overlay\n",
        "    ax2.imshow(mask, cmap='binary')\n",
        "    ax2.set_title(\"Binary Overlay\")\n",
        "    ax2.axis('off')\n",
        "    \n",
        "    # Combined overlay\n",
        "    ax3.imshow(base_image[..., :3])\n",
        "    ax3.imshow(overlay_rgba)\n",
        "    ax3.set_title(\"Overlay Result\")\n",
        "    ax3.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "display_overlay(input, pred_map)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZuITQMpZdGc"
      },
      "source": [
        "## Prediction Bucket Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "THIS DOES NOT WORK BECAUSE NOT IN THE GCLOUD ATM. Please import nessecary modules and figure this out if you need access here. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqgEmyg4VC7R"
      },
      "outputs": [],
      "source": [
        "# Function to download a TIFF file from a Google Cloud Storage bucket\n",
        "def download_tiff_from_bucket(file_path, bucket_name):\n",
        "    client = storage.Client()\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_path)\n",
        "    local_file_path = file_path.split('/')[-1]\n",
        "    blob.download_to_filename(local_file_path)\n",
        "    return local_file_path\n",
        "\n",
        "def process_tiff_file_from_bucket(file_path, bucket_name='greenland_delin_imagery'):\n",
        "    local_file_path = download_tiff_from_bucket(file_path, bucket_name)\n",
        "    return open_tiff(local_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRG7pYRWUSih"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.cloud import storage\n",
        "client = storage.Client()\n",
        "bucket = client.get_bucket('greenland_delin_imagery')\n",
        "blobs = bucket.list_blobs()\n",
        "# for file in files:\n",
        "#     print(file.name)\n",
        "\n",
        "\n",
        "# Create an empty list to store file names\n",
        "tif_files = []\n",
        "\n",
        "# Iterate over each blob\n",
        "for blob in blobs:\n",
        "    # Check if the file is a .tif file\n",
        "    if blob.name.endswith('.tif'):\n",
        "        # Append the blob name to the list\n",
        "        tif_files.append(blob.name)\n",
        "# Print out the list of .tif files\n",
        "for i in tif_files: print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEAj6jEwV7Do"
      },
      "outputs": [],
      "source": [
        "file_path = \"pred_batch_1/WVImagery/Minturn/Partial watershed 2019/WV02_20190804171102_103001009880B200_19AUG04171102-P1BS-503581603060_01_P003_u16rf3413-pred-v2.tif\"\n",
        "map = process_tiff_file_from_bucket(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFFIGTPpZgBt",
        "outputId": "69ff2db1-162d-4b1c-861a-9c9a393d2a1e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "import traceback\n",
        "import os\n",
        "\n",
        "from google.cloud import storage\n",
        "# Instantiate a Google Cloud Storage client\n",
        "client = storage.Client()\n",
        "\n",
        "# Specify your bucket\n",
        "bucket_name = 'greenland_delin_imagery'\n",
        "bucket = client.get_bucket(bucket_name)\n",
        "\n",
        "# List all the blobs in the bucket\n",
        "blobs = bucket.list_blobs()\n",
        "local_path = ''\n",
        "tiff_filepath = 'temp_download.tif'\n",
        "bucket_directory = 'pred_batch_2/'\n",
        "\n",
        "for blob in blobs:\n",
        "    if blob.name.endswith('.tif'):\n",
        "        try:\n",
        "            print(f\"Processing {blob.name}\")\n",
        "            blob.download_to_filename(tiff_filepath)\n",
        "\n",
        "            # Open the .tif file and extract the metadata\n",
        "            with rasterio.open(tiff_filepath) as src:\n",
        "                original_meta = src.meta\n",
        "\n",
        "            print(original_meta)\n",
        "            # Perform prediction\n",
        "            m = open_tiff(tiff_filepath, display_im=False)\n",
        "            m = normalize_to_8bit(m)\n",
        "            # Assuming m is normalized to [0, 1] range\n",
        "            pred_map_full = full_prediction_tiff(m, None, model_list, seg_connector)\n",
        "\n",
        "            # Convert predictions to binary (0 or 1) and then cast to int8\n",
        "            pred_map_full = (pred_map_full > 0.5).astype('int8')\n",
        "\n",
        "            try:\n",
        "              mask = (m == 0)\n",
        "              pred_map_full = pred_map_full * ~mask\n",
        "\n",
        "            except:\n",
        "              mask = (m[:,:,0] == 0)\n",
        "              pred_map_full = pred_map_full * ~mask\n",
        "\n",
        "            # Add a new dimension to represent single band if needed\n",
        "            if pred_map_full.ndim == 2:\n",
        "                pred_map_full = np.expand_dims(pred_map_full, axis=0)\n",
        "\n",
        "            # Update metadata for new file\n",
        "            new_meta = original_meta.copy()\n",
        "            new_meta['dtype'] = 'int8'\n",
        "            new_meta['count'] = pred_map_full.shape[0]\n",
        "            new_meta['compress'] = 'lzw'\n",
        "\n",
        "            # Create new file name for prediction\n",
        "            new_file_name = local_path + blob.name.replace('.tif', '-pred-v1.tif')\n",
        "\n",
        "            # Ensure the directory exists before attempting to write the file\n",
        "            os.makedirs(os.path.dirname(new_file_name), exist_ok=True)\n",
        "\n",
        "            # Write new file with updated metadata and prediction data\n",
        "            with rasterio.open(new_file_name, 'w', **new_meta) as dest:\n",
        "                dest.write(pred_map_full)\n",
        "\n",
        "            # Upload the prediction back to the bucket\n",
        "            pred_blob = bucket.blob(bucket_directory + blob.name.replace('.tif', '-pred-v1.tif'))\n",
        "            pred_blob.upload_from_filename(new_file_name)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Prediction failed for file: {blob.name}. Error: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "\n",
        "        finally:\n",
        "            # Delete the local files to free up memory\n",
        "            if os.path.isfile(tiff_filepath):\n",
        "                os.remove(tiff_filepath)\n",
        "            if os.path.isfile(new_file_name):\n",
        "                os.remove(new_file_name)\n",
        "\n",
        "        print(f\"Processing of {blob.name} complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m51rILfyU4ue"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  mask = (m == 0)\n",
        "  pred_map_full = pred_map_full * ~mask\n",
        "\n",
        "except:\n",
        "  mask = (m[:,:,0] == 0)\n",
        "  pred_map_full = pred_map_full * ~mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjW6w82bMTm_",
        "outputId": "539268f1-ca11-4ce4-c17e-5015f0cda704"
      },
      "outputs": [],
      "source": [
        "original_meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhaWTUSqROiM"
      },
      "outputs": [],
      "source": [
        "pred_map_full = np.squeeze(pred_map_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "MR5NdxZ_WBdx",
        "outputId": "d6c84071-1794-445b-a6f3-df93b8a2c20a"
      },
      "outputs": [],
      "source": [
        "display(pred_map_full[::5, ::5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnG7vdhNZZXV"
      },
      "source": [
        "## Prediction Individual Tiffs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkAPTu-oYafB",
        "outputId": "0ce8c23a-9fcc-40d0-808b-41486e2bdb16"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/My Drive/Projects/Mapping Glacial Rivers/Data/New_Data/for_mason/need_buffering\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8la9Kijc7AP",
        "outputId": "3c6bd7be-f76d-440f-c987-02f88ea43eb2"
      },
      "outputs": [],
      "source": [
        "input_tif_fp = \"/content/drive/My Drive/Projects/Mapping Glacial Rivers/Data/New_Data/for_mason/need_buffering/sn2_VIS.tif\"\n",
        "input = open_tiff(input_tif_fp,display_im=False)\n",
        "input = normalize_to_8bit(input)\n",
        "with rasterio.open(input_tif_fp) as src:\n",
        "    original_meta = src.meta\n",
        "    print(original_meta)\n",
        "stats(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqUkeKS5plET"
      },
      "outputs": [],
      "source": [
        "display(input[::20, ::20]) ## downscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIeAK8KQiq7c"
      },
      "outputs": [],
      "source": [
        "save_path = None\n",
        "print(input.shape)\n",
        "pred_map = full_prediction_tiff(input, save_path, model_list, seg_connector)\n",
        "print(pred_map.shape)\n",
        "try:\n",
        "  mask = (input == 0)\n",
        "  pred_map = pred_map * ~mask\n",
        "\n",
        "except:\n",
        "  mask = (input[:,:,0] == 0)\n",
        "  pred_map = pred_map * ~mask\n",
        "\n",
        "pred_map = pred_map.astype(np.uint8) # compress\n",
        "stats(pred_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "9d45FjnZbVo2",
        "outputId": "cf3a416f-aadc-4991-a5d2-602dd195c95a"
      },
      "outputs": [],
      "source": [
        "display(pred_map)\n",
        "#download_tiff(pred_map,original_meta, filename='sn2_pred.tif')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "8i1fYbzEDvHJ",
        "outputId": "83713760-66e9-427f-8cd9-1b74df127213"
      },
      "outputs": [],
      "source": [
        "display(pred_map[4000:7000, 4000:7000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC0_oxUBsO51",
        "outputId": "65639cc2-00ef-4880-8012-236a9ca0e887"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def count_files_in_directory(directory_path):\n",
        "    with os.scandir(directory_path) as entries:\n",
        "        return sum(1 for entry in entries if entry.is_file())\n",
        "\n",
        "directory_path = \"/content/drive/My Drive/Projects/Mapping Glacial Rivers/Data/New_Data/seg_connector_tiles/PredV3/mask\"\n",
        "file_count = count_files_in_directory(directory_path)\n",
        "print(f\"Number of files in directory: {file_count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn0eZzh8hMw-",
        "outputId": "a12c7300-e539-4ccf-d763-ca11e8fc7493"
      },
      "outputs": [],
      "source": [
        "gt_tif_fp = \"/content/drive/My Drive/Projects/Mapping Glacial Rivers/Data/New_Data/for_mason/need_buffering/sn2_gt.tif\"\n",
        "gt = open_tiff(input_tif_fp,display_im=False)\n",
        "gt = normalize_to_8bit(gt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x3YdRzoujUS8",
        "outputId": "fa379bac-3e40-4612-a73c-0fbd7bba8522"
      },
      "outputs": [],
      "source": [
        "display(gt)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "figNoyNmjwGp",
        "oN7TxA2CYhlh",
        "URksJ7wOjheb",
        "vjvM7gbtrU6t",
        "B4uFC8PgMGcs",
        "9WPIgkVzrQ7P"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
